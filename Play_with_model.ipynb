{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Play_lstm_seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crPVEDSN71sl"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khamies//LSTM-Language-Generator/blob/master/play_with_model.ipynb\" \n",
        "target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akHUDpl5RRWk",
        "cellView": "form",
        "outputId": "ee99fdd9-0c33-43b4-9f57-af543e6a724a"
      },
      "source": [
        "#@title Download data and files.\n",
        "!git clone https://github.com/Khamies/LSTM-Language-Generator.git\n",
        "import os \n",
        "os.chdir(\"LSTM-Language-Generator\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LSTM-Language-Generator'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 42 (delta 11), reused 33 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsX47UMWT0NT"
      },
      "source": [
        "import torch\n",
        "from data.ptb import PTB\n",
        "from model import LSTM_Language"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QyBIaJWGLI"
      },
      "source": [
        "# Settings\n",
        "\n",
        "torch.manual_seed(1000)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "batch_size = 32\n",
        "bptt = 60\n",
        "lr = 0.001\n",
        "\n",
        "embed_size = 300\n",
        "hidden_size = 256\n",
        "latent_size = 16\n",
        "lstm_layer=1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcXo1SRDfIVm"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2uVseOtT_4J"
      },
      "source": [
        "# Load the data\n",
        "train_data = PTB(data_dir=\"./data\", split=\"train\", create_data= False, max_sequence_length= bptt)\n",
        "test_data = PTB(data_dir=\"./data\", split=\"test\", create_data= False, max_sequence_length= bptt)\n",
        "valid_data = PTB(data_dir=\"./data\", split=\"valid\", create_data= False, max_sequence_length= bptt)\n",
        "\n",
        "# Batchify the data\n",
        "train_loader = torch.utils.data.DataLoader( dataset= train_data, batch_size= batch_size, shuffle= True)\n",
        "test_loader = torch.utils.data.DataLoader( dataset= test_data, batch_size= batch_size, shuffle= True)\n",
        "valid_loader = torch.utils.data.DataLoader( dataset= valid_data, batch_size= batch_size, shuffle= True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ2jOq3se8-x"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw2_Fc_9Vhh5",
        "outputId": "1e0886bb-8969-4d43-efbd-082656d391cb"
      },
      "source": [
        "vocab_size = train_data.vocab_size\n",
        "model = LSTM_Language(vocab_size = vocab_size, embed_size = embed_size, hidden_size = hidden_size, latent_size = latent_size).to(device)\n",
        "\n",
        "checkpoint = torch.load(\"models/LSTM_lang.pt\")\n",
        "model.load_state_dict(checkpoint[\"model\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4CNs1J4otu"
      },
      "source": [
        "##Sample Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKhUHL_7Vg5X",
        "cellView": "code",
        "outputId": "f3b2e51f-3e87-4eb6-f26d-6cd1aa70a639"
      },
      "source": [
        "sos = \"<sos>\"\n",
        "sample = model.inference(10 , sos)\n",
        "\n",
        "\n",
        "print(sample)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the company said it will sell $ n billion of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XvIj4l4QMi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}